<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="St. Schwarz" />

<meta name="date" content="2022-12-20" />

<title>DYN HA / SS22 FUB / Clara Liso</title>

<script src="DYN_HA_files/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="DYN_HA_files/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="DYN_HA_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="DYN_HA_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="DYN_HA_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="DYN_HA_files/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="DYN_HA_files/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="DYN_HA_files/tocify-1.9.1/jquery.tocify.js"></script>
<script src="DYN_HA_files/navigation-1.1/tabsets.js"></script>
<script src="DYN_HA_files/navigation-1.1/codefolding.js"></script>
<script src="DYN_HA_files/navigation-1.1/sourceembed.js"></script>
<link href="DYN_HA_files/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="DYN_HA_files/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>




<style type="text/css">
#rmd-source-code {
  display: none;
}
</style>

<style type="text/css">
/* for pandoc --citeproc since 2.11 */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="https://ada-sub.rotefadenbuecher.de/skool/public/papers/011/style_HA.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}

.tocify-subheader {
  display: inline;
}
.tocify-subheader .tocify-item {
  font-size: 0.95em;
}

</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-download-source" href="#">Download Rmd</a></li>
</ul>
</div>



<h1 class="title toc-ignore">DYN HA / SS22 FUB / Clara Liso</h1>
<h4 class="author">St. Schwarz</h4>
<h4 class="date">2022-12-20</h4>

</div>


<div id="a.-head" class="section level1" number="1">
<h1><span class="header-section-number">1</span> A. head</h1>
<p><img src="DYN_HA_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<hr />
</div>
<div id="einleitung" class="section level1" number="2">
<h1><span class="header-section-number">2</span> einleitung</h1>
<p>Wir werden im Folgenden den Versuch unternehmen, aus einigen statistischen Berechnungen Aussagen zum lyrischen Werk Uljana Wolfs abzuleiten. Ob daraus Erkenntnisse hinsichtlich des Aspekts <em>postdeutsch</em> erwachsen, können wir noch nicht sagen.
Die Arbeit wird explorativ vorgehen, dh. unser Erkenntnisinteresse ist durchaus ungerichtet. Wir wollen wesentlich einige Methoden zur Anwendung bringen, die geeignet erscheinen, weitere literaturwissenschaftliche Fragestellungen zu beantworten. Eine weiter gefasste Aufgabenstellung dieser Arbeit würde ca. lauten:</p>
<div id="fragestellung" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> fragestellung</h2>
<p>Bestimmung charakteristischer Merkmale im lyrischen Werk Uljana Wolfs mithilfe statistischer Methoden.</p>
</div>
</div>
<div id="zur-autorin" class="section level1" number="3">
<h1><span class="header-section-number">3</span> zur autorin</h1>
<p>Uljana Wolf, der Öffentlichkeit seit 2005 durch ihre Gedichte bekannt, wurde 2006 für ihr Debüt <em>kochanie ich habe brot gekauft</em> (kookbooks 2005) mit dem Peter-Huchel-Preis geehrt und veröffentlichte seitdem zwei weitere Gedichtbände, ebenfalls bei <em>kookbooks</em>. Dort ist sie in ein enges Netzwerk junger deutschsprachiger Autor:innen eingebunden, die sich auch (hier zum Aspekt <em>postdeutsch</em>) mehrheitlich durch ihre Affinität zu mehr- oder polylingualer Dichtung auszeichnen. Es gibt bei kook kaum Dichter:innen, deren Werk nicht irgendwie Mehrsprachigkeit künstlerisch umsetzt, damit arbeitet.</p>
</div>
<div id="work" class="section level1" number="4">
<h1><span class="header-section-number">4</span> work</h1>
<div id="corpus-aufbereitung" class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> corpus aufbereitung</h2>
<p>Das Korpus, welches nach Digitalisierung der Buchvorlagen aus einer Datenbank abgerufen wird, enthält 144 Einträge, nach Abzug der Kapitelüberschriften und Zitate 130 Datensätze (Texte), die zur Auswertung herangezogen werden können.
Für die Analyse wurde das gesamte (publizierte) lyrische Werk Uljana Wolfs, bestehend aus, in der Reihenfolge des Erscheinens:</p>
<ul>
<li>kochanie, ich habe Brot gekauft <span class="citation">(Wolf 2005)</span></li>
<li>falsche freunde <span class="citation">(Wolf 2009)</span></li>
<li>meine schönste lengevitch <span class="citation">(Wolf 2013)</span></li>
</ul>
<p>herangezogen.</p>
</div>
<div id="basic-statistics" class="section level2" number="4.2">
<h2><span class="header-section-number">4.2</span> basic statistics</h2>
<p>Wir werden versuchen, in der Arbeit einige Kennzahlen zu bestimmen, die charakteristisch für das Werk sein sollen. Basis sind hier Statistiken über Wortlängen und -frequenzen, Distribution multilingualer Elemente über das Korpus und Annäherungswerte zur Bestimmung des <em>sentiment</em>. Die Zahlen werden absolut und/oder relativ angegeben; absolut meint hier die konkrete Verortung an einer Position im Korpus, relativ meint jeweils die indexikalisierte, auf einer Gesamtheit v.H. angenommene Position oder Relation. Diese Relativierung ermöglicht eine gleichförmige Darstellung in glatten Frequenzkurven und veranschaulicht die Verhältnisse schematisch. (zur Berechnung der Fourier-transformierten (FFT) Frequenzen cf. <a href="https://www.matthewjockers.net/2015/02/02/syuzhet/"><span class="citation">(Jockers 2015)</span></a>)</p>
<div id="ground-truth" class="section level3" number="4.2.1">
<h3><span class="header-section-number">4.2.1</span> ground truth</h3>
<p>Die 130 Texte (Lyrik und lyrische oder experimentelle Prosa) haben einen Umfang von 10434 Wörtern (tokens), die sich in 3976 distinct types einteilen lassen, die type/token ratio, ein Indikator für <em>lexical diversity</em>, beträgt demnach 0.3810619. Die durchschnittliche Textlänge (median) beträgt 69 Wörter. Wir haben noch keine Vergleichswerte, die sinnvoll wären…</p>
</div>
<div id="multilx" class="section level3" number="4.2.2">
<h3><span class="header-section-number">4.2.2</span> multiLX</h3>
<p>Die multilingualen Elemente des Korpus (insgesamt 700 tokens) haben einen Anteil von 9% an den types.
Mit der Textmatrix (cf. Table <a href="#tab:text-matrix">1</a>) läszt sich noch weiter rechnen.</p>
<div class="figure"><span style="display:block;" id="fig:lx-matches"></span>
<img src="DYN_HA_files/figure-html/lx-matches-1.png" alt="multilingual elements over corpus" width="672" />
<p class="caption">
Figure 1: multilingual elements over corpus
</p>
</div>
</div>
<div id="similarities" class="section level3" number="4.2.3">
<h3><span class="header-section-number">4.2.3</span> similarities</h3>
<table style="width:100%;">
<caption><span id="tab:text-matrix">Table 1: </span><em>simplest matrix of text beginnings</em></caption>
<colgroup>
<col width="9%" />
<col width="8%" />
<col width="12%" />
<col width="11%" />
<col width="12%" />
<col width="14%" />
<col width="13%" />
<col width="17%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="left">gegen</td>
<td align="left">vier</td>
<td align="left">uhr</td>
<td align="left">morgens</td>
<td align="left">beobachte</td>
<td align="left">ich</td>
<td align="left">die</td>
<td align="left">verschiebung</td>
</tr>
<tr class="even">
<td align="left">ach</td>
<td align="left">wär</td>
<td align="left">ich</td>
<td align="left">nur</td>
<td align="left">im</td>
<td align="left">aufwachraum</td>
<td align="left">geblieben</td>
<td align="left">traumverloren</td>
</tr>
<tr class="odd">
<td align="left">ach</td>
<td align="left">wär</td>
<td align="left">ich</td>
<td align="left">nie</td>
<td align="left">im</td>
<td align="left">aufwachraum</td>
<td align="left">gewesen</td>
<td align="left">taub</td>
</tr>
<tr class="even">
<td align="left">schließ</td>
<td align="left">mich</td>
<td align="left">ein</td>
<td align="left">liebe</td>
<td align="left">ins</td>
<td align="left">gebet</td>
<td align="left">in</td>
<td align="left">die</td>
</tr>
<tr class="odd">
<td align="left">diese</td>
<td align="left">kästen</td>
<td align="left">enthalten</td>
<td align="left">frauen</td>
<td align="left">die</td>
<td align="left">nicht</td>
<td align="left">bearbeitet</td>
<td align="left">werden</td>
</tr>
<tr class="even">
<td align="left">meine</td>
<td align="left">väter</td>
<td align="left">sind</td>
<td align="left">einfache</td>
<td align="left">männer</td>
<td align="left">sie</td>
<td align="left">haben</td>
<td align="left">töchter</td>
</tr>
<tr class="odd">
<td align="left">meine</td>
<td align="left">väter</td>
<td align="left">sind</td>
<td align="left">keine</td>
<td align="left">einfachen</td>
<td align="left">männer</td>
<td align="left">sie</td>
<td align="left">haben</td>
</tr>
<tr class="even">
<td align="left">meine</td>
<td align="left">münder</td>
<td align="left">sind</td>
<td align="left">keine</td>
<td align="left">einfachen</td>
<td align="left">väter</td>
<td align="left">der</td>
<td align="left">erste</td>
</tr>
<tr class="odd">
<td align="left">meine</td>
<td align="left">väter</td>
<td align="left">sind</td>
<td align="left">einfache</td>
<td align="left">vermesser</td>
<td align="left">der</td>
<td align="left">erste</td>
<td align="left">geht</td>
</tr>
<tr class="even">
<td align="left">meine</td>
<td align="left">väter</td>
<td align="left">sind</td>
<td align="left">keine</td>
<td align="left">einfachen</td>
<td align="left">vermesser</td>
<td align="left">der</td>
<td align="left">erste</td>
</tr>
</tbody>
</table>
<p>Zum Beispiel lassen sich die Wortgleichungen visualisieren, die an bestimmten Positionen des Textes aufscheinen. Die Höhen in der folgenden Graphik markieren relative (Fourier-transformierte) Wortpositionen, an denen von Wolf die <strong>wenigsten</strong> analogen Wörter verwendet wurden. Es läszt sich erkennen, dasz ein Text meist mit denselben Wörtern anfängt (baisse), die immer verschiedener werden, um sich bei der Hälfte des Textes über eine lange Strecke zu gleichen und ab 60% sprunghaft zu divergieren bis sie um 78% einen peak (hausse) erreichen an Verschiedenheit.</p>
<div class="figure"><span style="display:block;" id="fig:text-sim-gr"></span>
<img src="DYN_HA_files/figure-html/text-sim-gr-1.png" alt="distinctness of word positions" width="672" />
<p class="caption">
Figure 2: distinctness of word positions
</p>
</div>
<p>Eine weiterhin schöne Graphik entsteht, wenn man die Matrix der Zeichenanzahl über die Gesamtheit der Wörter visualisiert. Hier zeigt sich, dasz ein Text zwischen 21-31% die längsten Wörter (mean: 9.5 characters) enthält, diese zwischen 36 und 56% kürzer werden bishin zu 7.76 Zeichen um bei 76% einen erneuten peak in der Zeichenanzahl (mean: 8.98 characters) zu erreichen.</p>
<div class="figure"><span style="display:block;" id="fig:wc"></span>
<img src="DYN_HA_files/figure-html/wc-1.png" alt="characters per position" width="672" />
<p class="caption">
Figure 3: characters per position
</p>
</div>
</div>
</div>
<div id="sentiment-analysis" class="section level2" number="4.3">
<h2><span class="header-section-number">4.3</span> sentiment analysis</h2>
<p>Für jeden einzelnen Text liesz sich ein Wert bestimmen, der Aussagen darüber zuläszt, in welchem Spektrum (positive/negative sentiment) sich dieser verorten läszt.
Die absoluten <em>sentiment values</em> werden weiterhin durch Fourier-Transformation auf die Gesamtheit des Korpus projiziert, um eine glatte, von der absoluten Position unabhängige Darstellung zu ermöglichen. (cf. Figure <a href="#fig:sent-freq">10</a>).
Welche Aussagen sich aus diesen Erkenntnissen ableiten lassen sollen, ist mir noch nicht ganz klar. I will elaborate on that.</p>
<div id="visualisation" class="section level3" number="4.3.1">
<h3><span class="header-section-number">4.3.1</span> visualisation</h3>
<div class="figure"><span style="display:block;" id="fig:sent-abs"></span>
<img src="DYN_HA_files/figure-html/sent-abs-1.png" alt="absolute *sentiment values* über das gesamte Textkorpus" width="672" />
<p class="caption">
Figure 4: absolute <em>sentiment values</em> über das gesamte Textkorpus
</p>
</div>
<div class="figure"><span style="display:block;" id="fig:sent-koch"></span>
<img src="DYN_HA_files/figure-html/sent-koch-1.png" alt="absolute *sentiment values* über *kochanie ich habe brot gekauft*" width="672" />
<p class="caption">
Figure 5: absolute <em>sentiment values</em> über <em>kochanie ich habe brot gekauft</em>
</p>
</div>
<div class="figure"><span style="display:block;" id="fig:sent-ff"></span>
<img src="DYN_HA_files/figure-html/sent-ff-1.png" alt="absolute *sentiment values* über *falsche freunde*" width="672" />
<p class="caption">
Figure 6: absolute <em>sentiment values</em> über <em>falsche freunde</em>
</p>
</div>
<div class="figure"><span style="display:block;" id="fig:sent-leng"></span>
<img src="DYN_HA_files/figure-html/sent-leng-1.png" alt="absolute *sentiment values* über *meine schönste lengevitch*" width="672" />
<p class="caption">
Figure 7: absolute <em>sentiment values</em> über <em>meine schönste lengevitch</em>
</p>
</div>
<p>Wir sehen in der frequenzanalysierten Graphik, dasz sich die relative Verteilung der sentiment values über die Bücher in der Tendenz unterscheidet. Während in <em>kochanie</em> und <em>lengevitch</em> schon zu Beginn Höhen verzeichnet sind, die Werte dann zur Buchmitte hin sinken, zeigt sich bei <em>FF</em> ein erster Wechsel von negativ zu positiv schon im ersten Drittel. Die Stimmung aller drei Bücher ist in der Mitte gleich negativ, in <em>kochanie</em> aber schon wieder aufsteigend, <em>falsche freunde</em> weist die gröszten Schwankungen auf.</p>
<div class="figure"><span style="display:block;" id="fig:sent-comp"></span>
<img src="DYN_HA_files/figure-html/sent-comp-1.png" alt="relative sentiment values singled" width="672" />
<p class="caption">
Figure 8: relative sentiment values singled
</p>
</div>
<div class="figure"><span style="display:block;" id="fig:sent-abs-cpt"></span>
<img src="DYN_HA_files/figure-html/sent-abs-cpt-1.png" alt="absolute *sentiment values* over corpus" width="672" />
<p class="caption">
Figure 9: absolute <em>sentiment values</em> over corpus
</p>
</div>
<p>In <em>kochanie</em> weisen die Werte die niedrigste, in <em>falsche freunde</em> die höchste Varianz auf.</p>
<div class="figure"><span style="display:block;" id="fig:sent-freq"></span>
<img src="DYN_HA_files/figure-html/sent-freq-1.png" alt="frequenzanalysierte (Fourier) *sentiment values* über Korpus" width="672" />
<p class="caption">
Figure 10: frequenzanalysierte (Fourier) <em>sentiment values</em> über Korpus
</p>
</div>
<div class="figure"><span style="display:block;" id="fig:sent-fr-cpt"></span>
<img src="DYN_HA_files/figure-html/sent-fr-cpt-1.png" alt="frequency analysis cf. [[@jockers_revealing_2015]](https://www.matthewjockers.net/2015/02/02/syuzhet/)" width="672" />
<p class="caption">
Figure 11: frequency analysis cf. <a href="https://www.matthewjockers.net/2015/02/02/syuzhet/"><span class="citation">(Jockers 2015)</span></a>
</p>
</div>
</div>
<div id="dependencies" class="section level3" number="4.3.2">
<h3><span class="header-section-number">4.3.2</span> dependencies</h3>
<p>Mit der Regressionsanalyse des <em>R lme4 package</em> <span class="citation">(Bates et al. 2015)</span> lassen sich hier Abhängigkeiten (Korrelationen) der <em>sentiment values</em> von verschiedenen Faktoren (chapter, book, multilingual elements) aufzeigen.</p>
<div id="lmer-bookchapter-dependency" class="section level4" number="4.3.2.1">
<h4><span class="header-section-number">4.3.2.1</span> lmer book/chapter dependency</h4>
<p>summary:</p>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: dta$sentiment ~ dta$book + (dta$book | dta$chapter)
##    Data: dta
## 
## REML criterion at convergence: 650.1
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -3.9330 -0.5158  0.0577  0.6694  2.7037 
## 
## Random effects:
##  Groups      Name               Variance Std.Dev. Corr             
##  dta$chapter (Intercept)        0.2986   0.5465                    
##              dta$bookFF         8.2772   2.8770    0.35            
##              dta$bookkochanie   0.2987   0.5465   -1.00 -0.35      
##              dta$booklengevitch 0.4123   0.6421   -0.87 -0.33  0.87
##  Residual                       8.9266   2.9877                    
## Number of obs: 131, groups:  dta$chapter, 12
## 
## Fixed effects:
##                      Estimate Std. Error t value
## (Intercept)         9.795e-16  3.037e+00   0.000
## dta$bookFF         -1.004e-15  4.386e+00   0.000
## dta$bookkochanie   -5.556e-01  3.070e+00  -0.181
## dta$booklengevitch -1.991e-01  3.065e+00  -0.065
## 
## Correlation of Fixed Effects:
##             (Intr) dt$bFF dt$bkk
## dta$bookFF  -0.693              
## dta$bokkchn -0.989  0.685       
## dt$bklngvtc -0.991  0.686  0.980
## optimizer (nloptwrap) convergence code: 0 (OK)
## boundary (singular) fit: see help(&#39;isSingular&#39;)</code></pre>
<div class="figure"><span style="display:block;" id="fig:sent-lm1"></span>
<img src="DYN_HA_files/figure-html/sent-lm1-1.png" alt="linear regression of sentiment dependencies, absolute" width="672" />
<p class="caption">
Figure 12: linear regression of sentiment dependencies, absolute
</p>
</div>
<p>Es ist zu zeigen, dasz die Abhängigkeit durchaus variiert. Die relativen Korrelationswerte schwanken zwischen -82 und 75 (bei f(x)=x/100), zwischen 40-80% läszt sich gröszere Abhängigkeit beobachten, dh. hier sind die sentiment values am stärksten vom Kapitel beeinfluszt, beispielhaft beim Text[82] <em>KLEINE STERNMULLREDE</em>, am wenigsten beim Text[104] <em>ANNALOG VON DEN BLUMEN</em>.</p>
<div class="figure"><span style="display:block;" id="fig:sent-lm-fr"></span>
<img src="DYN_HA_files/figure-html/sent-lm-fr-1.png" alt="linear regression of sentiment dependencies, relative" width="672" />
<p class="caption">
Figure 13: linear regression of sentiment dependencies, relative
</p>
</div>
</div>
<div id="lmer-multilx-dependency" class="section level4" number="4.3.2.2">
<h4><span class="header-section-number">4.3.2.2</span> lmer multiLX dependency</h4>
<p>Weiterhin können wir versuchen, eine Abhängigkeit der sentiment values von der Verwendung multilingualer Elemente aufzuzeigen. Die verdichteten schwarzen Balken (cf. Figure <a href="#fig:lx-matches">1</a>) korrelieren hier mit der roten Linie der Stimmungswerte, was eine Abhängigkeit vermuten läszt.</p>
<div class="figure"><span style="display:block;" id="fig:lx-sent-projection"></span>
<img src="DYN_HA_files/figure-html/lx-sent-projection-1.png" alt="absolute positioned multilingual elements over sentiment" width="672" />
<p class="caption">
Figure 14: absolute positioned multilingual elements over sentiment
</p>
</div>
<div class="figure"><span style="display:block;" id="fig:lx-sent-projection-f"></span>
<img src="DYN_HA_files/figure-html/lx-sent-projection-f-1.png" alt="percentage of multilingual elements over sentiment" width="672" />
<p class="caption">
Figure 15: percentage of multilingual elements over sentiment
</p>
</div>
<p>summary:</p>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: dta_t$sentiment ~ dta_t$book + (dta_t$book | dta_t$chapter) +  
##     (dta_t$lxp | dta_t$chapter) + (1 + dta_t$lxp) + (1 + dta_t$ttr)
##    Data: dta_t
## 
## REML criterion at convergence: 287.7
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -3.9484 -0.5075  0.0293  0.5177  3.4563 
## 
## Random effects:
##  Groups          Name                 Variance  Std.Dev. Corr             
##  dta_t.chapter   (Intercept)          0.2844653 0.53335                   
##                  dta_t$bookFF         0.2518810 0.50188  -0.03            
##                  dta_t$bookkochanie   0.2843860 0.53328  -1.00  0.03      
##                  dta_t$booklengevitch 0.2843925 0.53328  -1.00  0.03  1.00
##  dta_t.chapter.1 (Intercept)          0.0394181 0.19854                   
##                  dta_t$lxp            0.0001687 0.01299  -1.00            
##  Residual                             0.4794959 0.69246                   
## Number of obs: 131, groups:  dta_t$chapter, 12
## 
## Fixed effects:
##                       Estimate Std. Error t value
## (Intercept)          -1.391441   1.194420  -1.165
## dta_t$bookFF         -0.773382   1.166167  -0.663
## dta_t$bookkochanie   -0.590773   0.918345  -0.643
## dta_t$booklengevitch -0.641043   0.917044  -0.699
## dta_t$lxp             0.005018   0.008272   0.607
## dta_t$ttr             1.391441   0.789468   1.763
## 
## Correlation of Fixed Effects:
##             (Intr) dt_$FF dt_t$bkk dt_t$bkl dt_t$l
## dta_t$bokFF -0.624                                
## dt_t$bkkchn -0.820  0.761                         
## dt_t$bklngv -0.839  0.769  0.976                  
## dta_t$lxp   -0.083 -0.075  0.006   -0.057         
## dta_t$ttr   -0.661  0.072  0.133    0.160    0.125
## optimizer (nloptwrap) convergence code: 0 (OK)
## boundary (singular) fit: see help(&#39;isSingular&#39;)</code></pre>
<p>Die Abhängigkeit der sentiment values vom Vorhandensein multilingualer Elemente läszt sich kurz umreiszen: Wir stellen den gröszten Zusammenhang mit [coefficient] <code>4.6e-05</code> bei <code>dta_t$bookkochanie</code> fest, die Differenz zu <code>dta_t$bookFF</code> beträgt <code>7.74</code>, zu <code>dta_t$booklengevitch</code> <code>4.75</code> Punkte, der Abstand der Abhängigkeit hier also <code>2.99</code> Punkte.</p>
<p>Die Abhängigkeit der sentiment values von der type/token ratio der Texte ebenfalls kurz umrissen: Wir stellen den gröszten Zusammenhang mit [coefficient] <code>0.115873</code> bei <code>dta_t$booklengevitch</code> fest, die Differenz zu <code>dta_t$bookFF</code> beträgt <code>499.78</code>, zu <code>dta_t$bookkochanie</code> <code>195.96</code> Punkte, der Abstand der Abhängigkeit hier also <code>303.82</code> Punkte.</p>
</div>
</div>
<div id="in-words" class="section level3" number="4.3.3">
<h3><span class="header-section-number">4.3.3</span> in words</h3>
<p>summary:</p>
<pre><code>## [[1]]
## NULL
## 
## [[2]]
## [[2]]$min
## [[2]]$min$head
## [1] &quot;IV&quot;                  &quot;V legnica /liegnitz&quot;
## 
## [[2]]$min$book
## [1] &quot;kochanie&quot; &quot;kochanie&quot;
## 
## [[2]]$min$chapter
## [1] &quot;kochanie ich habe brot gekauft&quot; &quot;kochanie ich habe brot gekauft&quot;
## 
## [[2]]$min$id
## [1] &quot;126&quot; &quot;127&quot;
## 
## [[2]]$min$words
## [1] &quot;wir&quot; &quot;uns&quot;
## 
## 
## [[2]]$max
## [[2]]$max$head
## [1] &quot;reisende&quot;     &quot;übersetzen&quot;   &quot;post&quot;         &quot;knirschen II&quot; &quot;I&quot;           
## 
## [[2]]$max$book
## [1] &quot;kochanie&quot; &quot;kochanie&quot; &quot;kochanie&quot; &quot;kochanie&quot; &quot;kochanie&quot;
## 
## [[2]]$max$chapter
## [1] &quot;kochanie ich habe brot gekauft&quot; &quot;kochanie ich habe brot gekauft&quot;
## [3] &quot;kochanie ich habe brot gekauft&quot; &quot;kochanie ich habe brot gekauft&quot;
## [5] &quot;kochanie ich habe brot gekauft&quot;
## 
## [[2]]$max$id
## [1] &quot;129&quot; &quot;130&quot; &quot;133&quot; &quot;135&quot; &quot;136&quot;
## 
## [[2]]$max$words
## [1] &quot;no duplicate words&quot;
## 
## 
## 
## [[3]]
## [[3]]$min
## [[3]]$min$head
## [1] &quot;kreisau, nebelvoliere&quot;
## 
## [[3]]$min$book
## [1] &quot;kochanie&quot;
## 
## [[3]]$min$chapter
## [1] &quot;krzyżowa, gefährten&quot;
## 
## [[3]]$min$id
## [1] &quot;142&quot;
## 
## [[3]]$min$words
## [1] &quot;brust&quot; &quot;ein&quot;   &quot;halb&quot;  &quot;du&quot;    &quot;mich&quot;  &quot;ich&quot;   &quot;vogel&quot; &quot;dein&quot; 
## 
## 
## [[3]]$max
## [[3]]$max$head
## [1] &quot;an die kreisauer hunde&quot;          &quot;nachtrag an die kreisauer hunde&quot;
## 
## [[3]]$max$book
## [1] &quot;kochanie&quot; &quot;kochanie&quot;
## 
## [[3]]$max$chapter
## [1] &quot;krzyżowa, gefährten&quot; &quot;krzyżowa, gefährten&quot;
## 
## [[3]]$max$id
## [1] &quot;143&quot; &quot;144&quot;
## 
## [[3]]$max$words
## [1] &quot;euch&quot;   &quot;gehört&quot; &quot;jeden&quot;  &quot;meine&quot; 
## 
## 
## 
## [[4]]
## [[4]]$min
## [[4]]$min$head
## [1] &quot;fall - falls - fast - fell - flog&quot;
## 
## [[4]]$min$book
## [1] &quot;FF&quot;
## 
## [[4]]$min$chapter
## [1] &quot;DICHTionary&quot;
## 
## [[4]]$min$id
## [1] &quot;7&quot;
## 
## [[4]]$min$words
## [1] &quot;dir&quot;
## 
## 
## [[4]]$max
## [[4]]$max$head
## [1] &quot;kau - kind - kiss ~en&quot;
## 
## [[4]]$max$book
## [1] &quot;FF&quot;
## 
## [[4]]$max$chapter
## [1] &quot;DICHTionary&quot;
## 
## [[4]]$max$id
## [1] &quot;12&quot;
## 
## [[4]]$max$words
## [1] &quot;du&quot;  &quot;ein&quot;
## 
## 
## 
## [[5]]
## [[5]]$min
## [[5]]$min$head
## [1] &quot;REDE MIT AUFGEPICKTEM WORT&quot;
## 
## [[5]]$min$book
## [1] &quot;lengevitch&quot;
## 
## [[5]]$min$chapter
## [1] &quot;BRICKLEBRIT&quot;
## 
## [[5]]$min$id
## [1] &quot;40&quot;
## 
## [[5]]$min$words
## [1] &quot;zügel&quot;      &quot;mit&quot;        &quot;steht&quot;      &quot;nicht&quot;      &quot;man&quot;       
## [6] &quot;schabracke&quot; &quot;flur&quot;       &quot;hier&quot;      
## 
## 
## [[5]]$max
## [[5]]$max$head
## [1] &quot;REDE MIT LANGEN LEINEN&quot; &quot;KLEINE STERNMULLREDE&quot;  
## 
## [[5]]$max$book
## [1] &quot;lengevitch&quot; &quot;lengevitch&quot;
## 
## [[5]]$max$chapter
## [1] &quot;BRICKLEBRIT&quot; &quot;BRICKLEBRIT&quot;
## 
## [[5]]$max$id
## [1] &quot;34&quot; &quot;35&quot;
## 
## [[5]]$max$words
## [1] &quot;lining&quot;     &quot;man&quot;        &quot;fütterung&quot;  &quot;nicht&quot;      &quot;gedieht&quot;   
## [6] &quot;ein&quot;        &quot;ohne&quot;       &quot;gewissheit&quot; &quot;du&quot;        
## 
## 
## 
## [[6]]
## [[6]]$min
## [[6]]$min$head
## [1] &quot;TIMISOARA&quot;
## 
## [[6]]$min$book
## [1] &quot;lengevitch&quot;
## 
## [[6]]$min$chapter
## [1] &quot;MITTENS&quot;
## 
## [[6]]$min$id
## [1] &quot;47&quot;
## 
## [[6]]$min$words
##  [1] &quot;halb&quot;    &quot;&quot;        &quot;sie&quot;     &quot;lautet&quot;  &quot;erste&quot;   &quot;zeile&quot;   &quot;mit&quot;    
##  [8] &quot;fluss&quot;   &quot;während&quot; &quot;vorhang&quot; &quot;ein&quot;    
## 
## 
## [[6]]$max
## [[6]]$max$head
## [1] &quot;CORDOBA&quot;
## 
## [[6]]$max$book
## [1] &quot;lengevitch&quot;
## 
## [[6]]$max$chapter
## [1] &quot;MITTENS&quot;
## 
## [[6]]$max$id
## [1] &quot;46&quot;
## 
## [[6]]$max$words
## [1] &quot;&quot;      &quot;wir&quot;   &quot;jedes&quot; &quot;nach&quot;  &quot;ein&quot;   &quot;uns&quot;   &quot;mit&quot;  
## 
## 
## 
## [[7]]
## [[7]]$min
## [[7]]$min$head
## [1] &quot;III&quot;
## 
## [[7]]$min$book
## [1] &quot;lengevitch&quot;
## 
## [[7]]$min$chapter
## [1] &quot;KALTE KÜCHE&quot;
## 
## [[7]]$min$id
## [1] &quot;51&quot;
## 
## [[7]]$min$words
## [1] &quot;ein&quot;
## 
## 
## [[7]]$max
## [[7]]$max$head
## [1] &quot;I&quot;
## 
## [[7]]$max$book
## [1] &quot;lengevitch&quot;
## 
## [[7]]$max$chapter
## [1] &quot;KALTE KÜCHE&quot;
## 
## [[7]]$max$id
## [1] &quot;49&quot;
## 
## [[7]]$max$words
## [1] &quot;fichten&quot; &quot;für&quot;    
## 
## 
## 
## [[8]]
## [[8]]$min
## [[8]]$min$head
## [1] &quot;a&quot;
## 
## [[8]]$min$book
## [1] &quot;lengevitch&quot;
## 
## [[8]]$min$chapter
## [1] &quot;METHOD ACTING MIT ANNA 0.&quot;
## 
## [[8]]$min$id
## [1] &quot;59&quot;
## 
## [[8]]$min$words
##  [1] &quot;zeit&quot;        &quot;für&quot;         &quot;orangen&quot;     &quot;no&quot;          &quot;nicht&quot;      
##  [6] &quot;viel&quot;        &quot;ich&quot;         &quot;rundum&quot;      &quot;wand&quot;        &quot;orange&quot;     
## [11] &quot;sie&quot;         &quot;stundenlang&quot; &quot;keeps&quot;       &quot;me&quot;          &quot;wärterin&quot;   
## [16] &quot;mit&quot;         &quot;täglich&quot;     &quot;sies&quot;        &quot;gedacht&quot;     &quot;ehe&quot;        
## [21] &quot;tee&quot;         &quot;keine&quot;       &quot;time&quot;        &quot;wasser&quot;      &quot;eignes&quot;     
## [26] &quot;weil&quot;        &quot;züge&quot;        &quot;brücken&quot;     &quot;schiffchen&quot;  &quot;lack&quot;       
## [31] &quot;zeiten&quot;      &quot;were&quot;        &quot;mangel&quot;      &quot;ihr&quot;         &quot;geh&quot;        
## [36] &quot;esse&quot;        &quot;doktor&quot;     
## 
## 
## [[8]]$max
## [[8]]$max$head
## [1] &quot;d&quot;
## 
## [[8]]$max$book
## [1] &quot;lengevitch&quot;
## 
## [[8]]$max$chapter
## [1] &quot;METHOD ACTING MIT ANNA 0.&quot;
## 
## [[8]]$max$id
## [1] &quot;62&quot;
## 
## [[8]]$max$words
## [1] &quot;my&quot;
## 
## 
## 
## [[9]]
## [[9]]$min
## [[9]]$min$head
## [1] &quot;c&quot;
## 
## [[9]]$min$book
## [1] &quot;lengevitch&quot;
## 
## [[9]]$min$chapter
## [1] &quot;SPITZEN&quot;
## 
## [[9]]$min$id
## [1] &quot;72&quot;
## 
## [[9]]$min$words
## [1] &quot;they&quot;   &quot;ohr&quot;    &quot;pine&quot;   &quot;collar&quot; &quot;form&quot;  
## 
## 
## [[9]]$max
## [[9]]$max$head
## [1] &quot;g&quot;
## 
## [[9]]$max$book
## [1] &quot;lengevitch&quot;
## 
## [[9]]$max$chapter
## [1] &quot;SPITZEN&quot;
## 
## [[9]]$max$id
## [1] &quot;75&quot;
## 
## [[9]]$max$words
## [1] &quot;schaut&quot;
## 
## 
## 
## [[10]]
## [[10]]$min
## [[10]]$min$head
## [1] &quot;IV&quot;
## 
## [[10]]$min$book
## [1] &quot;lengevitch&quot;
## 
## [[10]]$min$chapter
## [1] &quot;BOUGAINVILLE&quot;
## 
## [[10]]$min$id
## [1] &quot;82&quot;
## 
## [[10]]$min$words
## [1] &quot;nach&quot; &quot;sag&quot; 
## 
## 
## [[10]]$max
## [[10]]$max$head
## [1] &quot;III&quot;
## 
## [[10]]$max$book
## [1] &quot;lengevitch&quot;
## 
## [[10]]$max$chapter
## [1] &quot;BOUGAINVILLE&quot;
## 
## [[10]]$max$id
## [1] &quot;81&quot;
## 
## [[10]]$max$words
## [1] &quot;finde&quot; &quot;sie&quot;   &quot;mit&quot;  
## 
## 
## 
## [[11]]
## [[11]]$min
## [[11]]$min$head
## [1] &quot;BABELTRACK\n\n(NOTIZEN ZU EINER LENGEVITCH)&quot;
## 
## [[11]]$min$book
## [1] &quot;lengevitch&quot;
## 
## [[11]]$min$chapter
## [1] &quot;BABELTRACK&quot;
## 
## [[11]]$min$id
## [1] &quot;87&quot;
## 
## [[11]]$min$words
##  [1] &quot;ich&quot;     &quot;wollte&quot;  &quot;man&quot;     &quot;kind&quot;    &quot;stehlen&quot; &quot;mein&quot;    &quot;warum&quot;  
##  [8] &quot;tal&quot;     &quot;kommen&quot;  &quot;mich&quot;    &quot;meinen&quot;  &quot;ihr&quot;    
## 
## 
## [[11]]$max
## [[11]]$max$head
## [1] &quot;BABELTRACK\n\n(NOTIZEN ZU EINER LENGEVITCH)&quot;
## 
## [[11]]$max$book
## [1] &quot;lengevitch&quot;
## 
## [[11]]$max$chapter
## [1] &quot;BABELTRACK&quot;
## 
## [[11]]$max$id
## [1] &quot;85&quot;
## 
## [[11]]$max$words
## [1] &quot;werden&quot;      &quot;milchbahnen&quot; &quot;festländer&quot;  &quot;insel&quot;       &quot;sprache&quot;    
## [6] &quot;macht&quot;       &quot;mit&quot;         &quot;blase&quot;       &quot;sie&quot;</code></pre>
<style type="text/css">
pre {max-height: 400px;}
#most-probable-text p {font-family: Courier;}
</style>
<p>Zum Beispiel: Die höchsten <em>sentiment</em> Werte, hier in [chapter:] <code>krzyżowa, gefährten, krzyżowa, gefährten</code>, lassen sich in [text:] <code>an die kreisauer hunde, nachtrag an die kreisauer hunde</code> finden. Die <em>most frequent words</em> dieses Abschnitts sind [duplicates:] <code>euch, gehört, jeden, meine</code>, die niedrigsten finden sich im Text <code>kreisau, nebelvoliere</code> mit <code>brust, ein, halb, du, mich, ich, vogel, dein</code>.</p>
</div>
</div>
<div id="corpus-play" class="section level2" number="4.4">
<h2><span class="header-section-number">4.4</span> corpus play</h2>
<p>Das Folgende zeigt einen Text, dem ein Algoritmus zugrundeliegt, der roughly die Wahrscheinlichkeit des Vorhandenseins eines Wortes an der jeweiligen Position im Text, über den gesamten Korpus betrachtet, bestimmt. Es tritt also jedes Wort dieses künstlichen Textes am wahrscheinlichsten an dieser Stelle auf, szsg. ein sehr simples <em>transformer</em> experiment, ohne jegliche Berücksichtigung semantisch-syntaktischer Kategorien.</p>
<div id="most-probable-text" class="section level3" number="4.4.1">
<h3><span class="header-section-number">4.4.1</span> most probable text</h3>
<p>13506.ST: Uljana Wolf / GPTestee
&lt;&lt;&lt;
i a a a der a a i der a in i i b in in i a a er a es in er a d h in i a der in in a in in in a i er er in ich a a in in in in u er in i in a in in in ich i in er in u a in a a in in in a a i in ich ein und in i in in in in in a u der ich an in in ein der a es in der er der in se ein in in es ich es die in u t ich in die an die in ein der ich ich die ich in die die die der de der er der ein ich auf die u ich es me die das ich die eine auf die zu so ich war der da als der er ehe ich über nicht und am es ich hab ich nicht den hat es so ist und kann ist es die zeit die time at and für man für oder ich in die mit ehe ich it in blick eine weil wenn sonst ich sage das me things der all nicht go sie use ich her die rum es auch die ein orangen oder am und ich oder in die es ist nicht um in ist es keine and no für at all end of die the und es die auf in orangen ist es und sich über nicht at all ich aus so bis an oh sind sie und ein ich das ich sei so von an ist die sie putzen aus der haben wir mit ein bis die türen kaum und sie seine zu auf a straße is ich sagen a by is die one von ihre und essen durch nur ziehen und sagen we ehe a herkunft und such nein ich habe nicht und ich so we will see nicht wahr all the ein hund be recht auf seinen freigang hat aber dass orangen
&lt;&lt;&lt; fin.</p>
<hr />
</div>
</div>
</div>
<div id="b.-ref" class="section level1 unnumbered">
<h1>B. REF:</h1>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-bates_fitting_2015" class="csl-entry">
Bates, Douglas, Martin Mächler, Ben Bolker, and Steve Walker. 2015. <span>“Fitting <span>Linear</span> <span>Mixed</span>-<span>Effects</span> <span>Models</span> <span>Using</span> Lme4.”</span> <em>Journal of Statistical Software</em> 67 (1): 1–48. <a href="https://doi.org/10.18637/jss.v067.i01">https://doi.org/10.18637/jss.v067.i01</a>.
</div>
<div id="ref-jockers_revealing_2015" class="csl-entry">
Jockers, Matthew L. 2015. <span>“Revealing <span>Sentiment</span> and <span>Plot</span> <span>Arcs</span> with the <span>Syuzhet</span> <span>Package</span> <span>Matthew</span> <span>L</span>. <span>Jockers</span>.”</span> <a href="https://www.matthewjockers.net/2015/02/02/syuzhet/">https://www.matthewjockers.net/2015/02/02/syuzhet/</a>.
</div>
<div id="ref-wolf_kochanie_2005" class="csl-entry">
Wolf, Uljana. 2005. <em>Kochanie Ich Habe Brot Gekauft: <span>Gedichte</span> / <span>Uljana</span> <span>Wolf</span>.</em> 1. Aufl. Reihe <span>Lyrik</span> 5. Idstein: Kookbooks.
</div>
<div id="ref-wolf_falsche_2009" class="csl-entry">
———. 2009. <em>Falsche <span>Freunde</span>: <span>Gedichte</span> / <span>Uljana</span> <span>Wolf</span>.</em> 1. Aufl. Kookbooks : <span>Reihe</span> <span>Lyrik</span> 15. Idstein: kookbooks.
</div>
<div id="ref-wolf_meine_2013" class="csl-entry">
———. 2013. <em>Meine Schönste <span>Lengevitch</span>: <span>Gedichte</span> / <span>Uljana</span> <span>Wolf</span>.</em> 1. Auflage. Reihe <span>Lyrik</span> <span>Band</span> 32. Berlin: kookbooks.
</div>
</div>
</div>

<div id="rmd-source-code">---
#--- official ---#
# Hausarbeit im Seminar: Dynamiken postdeutscher Gegenwartsliteratur, Clara Liso, SS2022 FUB
# im Fach: Allgemeine und Vergleichende Literaturwissenschaften
# eingereicht von Stephan Schwarz
# Abgabe: due

title: "DYN HA / SS22 FUB / Clara Liso"
author: "St. Schwarz"
date: "`r Sys.Date()`"
zotero: AVL_dyn
output: 
  bookdown::html_document2:
    global_numbering: TRUE
    number_sections: TRUE
    code_download: yes
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: no
    self_contained: FALSE #TRUE for standalone html page knit
    #css: ../style_HA.css
#swap / decomment ff .bib/.css references for self compile .Rmd to html
#bibliography: https://raw.githubusercontent.com/esteeschwarz/DH_essais/main/sections/DYN/DYN_HA/DYN_HA.bib
    css: https://ada-sub.rotefadenbuecher.de/skool/public/papers/011/style_HA.css
bibliography: DYN_HA.bib
---
# A. head
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#mini critical: dont find relative files in path
#knitr::opts_knit$set(root.dir="~/boxHKW/21S/DH")
#knitr::opts_knit$set(base.dir = "~/boxHKW/21S/DH/gith/DH_essais/sections/DYN/DYN_HA")
#EWA, lapsi
#knitr::opts_knit$set(root.dir="~/boxHKW/UNI/21S/DH")
#knitr::opts_knit$set(base.dir = "~/boxHKW/UNI/21S/DH/gith/DH_essais/sections/DYN/DYN_HA")

```

```{r eval=TRUE, echo=FALSE, warning=FALSE,message=FALSE}
library(httr)
#fetch zotero .bib online
#share <- runif(1)
x<-GET("https://api.zotero.org/groups/4713246/collections/9LNRRJQN/items/top?format=bibtex")
bib<-content(x,"text")
#ref1<-citation("lme4")
#ref2<-print(ref1,style="bibtex")
#ref2
#bib2
#print(bib,style="bibtex")
#b4<-bibentry(b)
y<-tempfile("ref",fileext = ".bib")
#blm<-toBibtex(ref1)
writeLines(bib,y)
#b3<-unlist(bib2)
#print(b,style="Bibtex")
#b<-pandoc_citeproc_convert(y)
#bib2<-append(b,ref1,after = length(b))
#x<-readLines(y)
#b5<-readCitationFile()
#b7<-citation("lme4")
#toBibtex(b7)
```
---
bibliography: "`r y`"
---
```{r eval=TRUE, echo=FALSE, warning=FALSE,message=FALSE}
library(mongolite)
library(jsonlite)
library(syuzhet)
library(readr)
library(ggplot2)
library(lme4)
library(stringi)
library(stringr)
library(rmarkdown)



#root<-"/Users/lion/boxHKW/21S/DH/"
#local<-paste0(root,"local/DYN/")
#setwd("~/boxHKW/21S/DH")
#src<-"wolf_FF_1.json"
#src<-paste0(local,"wolf_FF-LEN_1.json")
#getwd()
src<-"../../../../../local/R/cred_gener.csv"
  cred<-read.csv(src)
#  con<- mongo(collection = "wolfdb003", db ="deadend", url=cred$url[cred$q=="mongodb"])
 #   dta<-con$find('{}')
#local data:
    src<-"../../../../../local/DYN/db/wolfdb003.csv"
    src_lx<-"../../../../../local/DYN/db/tokensMultiLX_m.csv"

    dta<-read.csv(src)
    lxtable<-read_csv2(src_lx)
    mlx<-subset(lxtable,lxtable$multi=="multiLX")

    dta_sf<-dta
#k<-2
#dtatxt<-as.data.frame(fromJSON(src))
#dtatxt<-(fromJSON(src))
#cat("load TEI from:",src)
    src<-"DYN_HA_semantics.R"
#source("/gith/DH_essais/sections/DYN/DYN_HA/DYN_HA_semantics.R")
   source(src)
  lc<-length(dta$content)-1

    
```

---

# einleitung
Wir werden im Folgenden den Versuch unternehmen, aus einigen statistischen Berechnungen Aussagen zum lyrischen Werk Uljana Wolfs abzuleiten. Ob daraus Erkenntnisse hinsichtlich des Aspekts *postdeutsch* erwachsen, können wir noch nicht sagen.
Die Arbeit wird explorativ vorgehen, dh. unser Erkenntnisinteresse ist durchaus ungerichtet. Wir wollen wesentlich einige Methoden zur Anwendung bringen, die geeignet erscheinen, weitere literaturwissenschaftliche Fragestellungen zu beantworten. Eine weiter gefasste Aufgabenstellung dieser Arbeit würde ca. lauten:

## fragestellung
Bestimmung charakteristischer Merkmale im lyrischen Werk Uljana Wolfs mithilfe statistischer Methoden. 

# zur autorin
Uljana Wolf, der Öffentlichkeit seit 2005 durch ihre Gedichte bekannt, wurde 2006 für ihr Debüt *kochanie ich habe brot gekauft* (kookbooks 2005) mit dem Peter-Huchel-Preis geehrt und veröffentlichte seitdem zwei weitere Gedichtbände, ebenfalls bei *kookbooks*. Dort ist sie in ein enges Netzwerk junger deutschsprachiger Autor:innen eingebunden, die sich auch (hier zum Aspekt *postdeutsch*) mehrheitlich durch ihre Affinität zu mehr- oder polylingualer Dichtung auszeichnen. Es gibt bei kook kaum Dichter:innen, deren Werk nicht irgendwie Mehrsprachigkeit künstlerisch umsetzt, damit arbeitet. 

# work
## corpus aufbereitung
Das Korpus, welches nach Digitalisierung der Buchvorlagen aus einer Datenbank abgerufen wird, enthält `r length(dta_sf$content)` Einträge, nach Abzug der Kapitelüberschriften und Zitate `r length(dta$content)-1` Datensätze (Texte), die zur Auswertung herangezogen werden können.
Für die Analyse wurde das gesamte (publizierte) lyrische Werk Uljana Wolfs, bestehend aus, in der Reihenfolge des Erscheinens:

- kochanie, ich habe Brot gekauft [@wolf_kochanie_2005]
- falsche freunde [@wolf_falsche_2009]
- meine schönste lengevitch [@wolf_meine_2013]

herangezogen.

## basic statistics
```{r echo = FALSE,warning=FALSE}
# wolfcpt<-dta$content
# wolftokens<-stri_count_boundaries(wolfcpt,"word")
# dta$tokens<-wolftokens
# tk1<-dta$tokens[dta$book_id==1]
# tk2<-dta$tokens[dta$book_id==2]
# tk3<-dta$tokens[dta$book_id==3]
# stk1<-sum(tk1,na.rm = T)
# stk2<-sum(tk2,na.rm = T)
# stk3<-sum(tk3,na.rm = T)
# stkcpt<-sum(dta$tokens,na.rm = T)
# wolfcpt_s<-stri_split_boundaries(dta$content,type="word")
# wolfcpt_s
md_t<-median(dta_t$tokens) #durchschnittliche textlänge
#dta_t$types
#set$types
min_t<-min(dta_t$tokens[2:length(dta_t$tokens)])
#lxtable<-get_lxtable(src_lx)
mlx<-subset(lxtable,lxtable$multi=="multiLX")
lmlx<-length(mlx$lxtok)
mlx_u<-unique(mlx$lxtok[1:lmlx])
tokenarray<-get_tarray()
token_na<-tokenarray[!is.na(tokenarray)]
lto<-length(token_na)
lty<-length(unique(token_na))

#700/20000
```

Wir werden versuchen, in der Arbeit einige Kennzahlen zu bestimmen, die charakteristisch für das Werk sein sollen. Basis sind hier Statistiken über Wortlängen und -frequenzen, Distribution multilingualer Elemente über das Korpus und Annäherungswerte zur Bestimmung des *sentiment*. Die Zahlen werden absolut und/oder relativ angegeben; absolut meint hier die konkrete Verortung an einer Position im Korpus, relativ meint jeweils die indexikalisierte, auf einer Gesamtheit v.H. angenommene Position oder Relation. Diese Relativierung ermöglicht eine gleichförmige Darstellung in glatten Frequenzkurven und veranschaulicht die Verhältnisse schematisch. (zur Berechnung der Fourier-transformierten (FFT) Frequenzen cf. [[@jockers_revealing_2015]](https://www.matthewjockers.net/2015/02/02/syuzhet/))

### ground truth
Die `r lc` Texte (Lyrik und lyrische oder experimentelle Prosa) haben einen Umfang von `r lto` Wörtern (tokens), die sich in `r lty` distinct types einteilen lassen, die type/token ratio, ein Indikator für *lexical diversity*, beträgt demnach `r lty/lto`. Die durchschnittliche Textlänge (median) beträgt `r md_t` Wörter. Wir haben noch keine Vergleichswerte, die sinnvoll wären...

### multiLX
Die multilingualen Elemente des Korpus (insgesamt `r lmlx` tokens) haben einen Anteil von `r round(length(mlx_u)/lty*100)`% an den types.
Mit der Textmatrix (cf. Table \@ref(tab:text-matrix)) läszt sich noch weiter rechnen.

```{r lx-matches, echo=F,fig.cap="multilingual elements over corpus",warning=FALSE}
#lxm_f<-get_transformed_values(get_lxmatches())
sent_global_f<-get_transformed_values(sent_global)
plot(get_lxmatches(),type = "h",xlab="text corpus",ylab="occurences", main="occurences of non german words")
#par(new=T)
#plot(sent_global_f,type = "h",col=2,xaxt="n",yaxt="n",ann = F)

#scatter.smooth(1:length(sent_global),sent_global,.1,.1,type="l",family = "gaussian",col=2,xaxt="n",yaxt="n",ann = F)
```

### similarities
```{r text-matrix, echo = F,warning=FALSE}
knitr::kable(wolfmatrix[1:10, 1:8], caption = "*simplest matrix of text beginnings*")
end<-50
#typearray numbers:
maxty<-which.max(typearray_f)
maxch<-which.max(chararray_f)
maxch_n<-max(chararray_f)
maxch0<-maxch-5
maxch1<-maxch+5
mdch<-median(chararray_f)
mdp<-grep(round(mdch,2),chararray_f)
minch_n<-min(chararray_f[mdp])
max2<-which.max(chararray_f[maxch1+5:length(chararray_f)])
#max3<-length(chararray_f)-maxch1+5
max3<-maxch1+5+max2
```

Zum Beispiel lassen sich die Wortgleichungen visualisieren, die an bestimmten Positionen des Textes aufscheinen. Die Höhen in der folgenden Graphik markieren relative (Fourier-transformierte) Wortpositionen, an denen von Wolf die **wenigsten** analogen Wörter verwendet wurden. Es läszt sich erkennen, dasz ein Text meist mit denselben Wörtern anfängt (baisse), die immer verschiedener werden, um sich bei der Hälfte des Textes über eine lange Strecke zu gleichen und ab 60% sprunghaft zu divergieren bis sie um `r maxty`% einen peak (hausse) erreichen an Verschiedenheit.

```{r text-sim-gr,fig.cap="distinctness of word positions", echo = F,warning=FALSE}
#end<-50
#plot(typearray[1:50],type="h",xlab = paste0("first ", end," words of texts"),ylab="count of distinct types")
# scatter.smooth(1:end,typearray[1:end],.1,.1,type="h",family = "gaussian",ylab="count of distinct types",xlab = paste0("first ", end," words of texts"))
scatter.smooth(1:length(typearray_f),typearray_f,.1,.1,type="h",family = "gaussian",ylab="mean of distinct types",xlab = "relative position of words in texts")

```

Eine weiterhin schöne Graphik entsteht, wenn man die Matrix der Zeichenanzahl über die Gesamtheit der Wörter visualisiert. Hier zeigt sich, dasz ein Text zwischen `r maxch0`-`r maxch1`% die längsten Wörter (mean: `r round(maxch_n,2)` characters) enthält, diese zwischen `r mdp[1]` und `r mdp[2]`% kürzer werden bishin zu `r round(minch_n,2)` Zeichen um bei `r max3`% einen erneuten peak in der Zeichenanzahl (mean: `r round(chararray_f[max3],2)` characters) zu erreichen.

```{r wc,fig.cap="characters per position", echo = F,warning=FALSE}
#end<-50
scatter.smooth(1:length(chararray_f),chararray_f,.1,.1,type="h",family = "gaussian",ylab="mean count of characters",xlab = "relative position of words in texts")

#image(wc,xaxt="n",yaxt="n",xlab="textposition in corpus",ylab="wordposition in #text")
```

## sentiment analysis
Für jeden einzelnen Text liesz sich ein Wert bestimmen, der Aussagen darüber zuläszt, in welchem Spektrum (positive/negative sentiment) sich dieser verorten läszt.
Die absoluten *sentiment values* werden weiterhin durch Fourier-Transformation auf die Gesamtheit des Korpus projiziert, um eine glatte, von der absoluten Position unabhängige Darstellung zu ermöglichen. (cf. Figure \@ref(fig:sent-freq)).
Welche Aussagen sich aus diesen Erkenntnissen ableiten lassen sollen, ist mir noch nicht ganz klar. I will elaborate on that.

### visualisation
```{r eval=TRUE, echo=FALSE, collapse=TRUE, warning=FALSE,message=FALSE}
#calls miracle function from external script:
#book<-3
#chapter<-3
#plot_abs<-0
#text<-2
#dtatarget<-plotsentiment(dtatxt,book,chapter,plot_abs,3) #ARG: (set,book,chapter,absolute)
#out dta_t<-get_types(dta,1)
le<-do_sentiment(dta_t)
mfw_dta<-list()
for (k in 2: length(chapter_ex)){
  

mfw_dta[[k]]<-mfw(dta,k)
}
#mfw_dta[[3]]$max$id
```

```{r sent-abs, fig.cap="absolute *sentiment values* über das gesamte Textkorpus",echo=FALSE}
 # sent2<-c(a1,a2,a3) #untransformed sentiment, absolute
  scatter.smooth(1:length(le$sentiment$cpt_s2),le$sentiment$cpt_s2,.1,.1,type="h",family = "gaussian",ylab="absolute sentiment vaules",xlab="text corpus",main="sentiment over texts")
```

```{r sent-koch, fig.cap="absolute *sentiment values* über *kochanie ich habe brot gekauft*",echo=FALSE}
  scatter.smooth(1:length(le$sentiment$a1),le$sentiment$a1,.1,.1,type="h",family = "gaussian",ylab="absolute sentiment vaules",xlab="text: kochanie",main="sentiment over texts")
```

```{r sent-ff, fig.cap="absolute *sentiment values* über *falsche freunde*",echo=FALSE}
  scatter.smooth(1:length(le$sentiment$a2),le$sentiment$a2,.1,.1,type="h",family = "gaussian",ylab="absolute sentiment vaules",xlab="text: FF",main="sentiment over texts")
```

```{r sent-leng, fig.cap="absolute *sentiment values* über *meine schönste lengevitch*",echo=FALSE}
  scatter.smooth(1:length(le$sentiment$a3),le$sentiment$a3,.1,.1,type="h",family = "gaussian",ylab="absolute sentiment vaules",xlab="text: lengevitch",main="sentiment over texts")
#  sent3<-get_transformed_values(sent2)
```

Wir sehen in der frequenzanalysierten Graphik, dasz sich die relative Verteilung der sentiment values über die Bücher in der Tendenz unterscheidet. Während in *kochanie* und *lengevitch* schon zu Beginn Höhen verzeichnet sind, die Werte dann zur Buchmitte hin sinken, zeigt sich bei *FF* ein erster Wechsel von negativ zu positiv schon im ersten Drittel. Die Stimmung aller drei Bücher ist in der Mitte gleich negativ, in *kochanie* aber schon wieder aufsteigend, *falsche freunde* weist die gröszten Schwankungen auf. 

```{r sent-comp,fig.cap="relative sentiment values singled",echo=FALSE}
par(new=F)
plot(le$sentiment$a1i,type = "h",col=4,ylab = "sentiment frequencies",xlab="blue: kochanie, red: FF, yellow: lengevitch",main="sentiment distribution over book")
par(new=T) #red
plot(le$sentiment$a2i,type = "h",col=2,xaxt="n",yaxt="n",ann = F)
par(new=T) #green
plot(le$sentiment$a3i,type = "h",col=7,xaxt="n",yaxt="n",ann = F) #blue
```

```{r sent-abs-cpt, fig.cap="absolute *sentiment values* over corpus",echo=FALSE}
  p<-ggplot(dta, aes(1:length(sentiment), sentiment, colour = book)) + 
    geom_line()
  p +  labs(x="corpus", y="sentiment absolute", title="sentiment over texts", fill="book")
```

In *kochanie* weisen die Werte die niedrigste, in *falsche freunde* die höchste Varianz auf. 

```{r sent-freq, fig.cap="frequenzanalysierte (Fourier) *sentiment values* über Korpus",echo=FALSE}
  plot(le$sentiment$cpt_s1,type = "h",col=2,ylab = "sentiment frequencies",xlab="corpus",main="sentiment over texts")
```

```{r sent-fr-cpt, fig.cap="frequency analysis cf. [[@jockers_revealing_2015]](https://www.matthewjockers.net/2015/02/02/syuzhet/)",echo=FALSE}
  plot(le$sentiment$cpt_s3,type = "h",col=2,ylab = "sentiment frequencies",xlab="corpus agglomerated",main="sentiment analysis over texts")
```

### dependencies
Mit der Regressionsanalyse des *R lme4 package* [@bates_fitting_2015] lassen sich hier Abhängigkeiten (Korrelationen) der *sentiment values* von verschiedenen Faktoren (chapter, book, multilingual elements) aufzeigen.

#### lmer book/chapter dependency
summary:
```{r sum-lmer, echo=FALSE}
print(le$lm$sum)
```

```{r sent-lm1, fig.cap="linear regression of sentiment dependencies, absolute",echo=FALSE}
  scatter.smooth(1:length(le$lm$sum$residuals),le$lm$sum$residuals,.1,.1,type="h",family = "gaussian",ylab="dependencies: lmer sentiment residuals",xlab="text corpus",main="sentiment book/chapter dependency")
depmax<-which.max(le$lm$sum$residuals)
depmin<-which.min(le$lm$sum$residuals)
depmaxr<-round(max(le$lm$scaled))
depminr<-round(min(le$lm$scaled))

#dta_t$phead[depmin]
#depmax
#length(le$lm$sum$residuals)
```

Es ist zu zeigen, dasz die Abhängigkeit durchaus variiert. Die relativen Korrelationswerte schwanken zwischen `r depminr` und `r depmaxr` (bei f(x)=x/100), zwischen 40-80% läszt sich gröszere Abhängigkeit beobachten, dh. hier sind die sentiment values am stärksten vom Kapitel beeinfluszt, beispielhaft beim Text[`r depmax`]  *`r dta_t$phead[depmax]`*, am wenigsten beim Text[`r depmin`]  *`r dta_t$phead[depmin]`*. 

```{r sent-lm-fr, fig.cap="linear regression of sentiment dependencies, relative",echo=FALSE}
  plot(le$lm$scaled,type = "h",col=2,ylab = "sentiment frequencies auf 100%",xlab="corpus",main="sentiment analysis over texts")
```

#### lmer multiLX dependency
Weiterhin können wir versuchen, eine Abhängigkeit der sentiment values von der Verwendung multilingualer Elemente aufzuzeigen. Die verdichteten schwarzen Balken (cf. Figure \@ref(fig:lx-matches)) korrelieren hier mit der roten Linie der Stimmungswerte, was eine Abhängigkeit vermuten läszt.

```{r lx-sent-projection, echo=F,fig.cap="absolute positioned multilingual elements over sentiment",warning=FALSE}
sent_global_f<-get_transformed_values(sent_global)
plot(get_lxmatches(),type = "h",xlab="text corpus",ylab="occurences",main="sentiment/language correlation")
par(new=T)
plot(sent_global_f,type = "l",col=2,xaxt="n",yaxt="n",ann = F)

#scatter.smooth(1:length(sent_global),sent_global,.1,.1,type="l",family = "gaussian",col=2,xaxt="n",yaxt="n",ann = F)
```

```{r lx-sent-projection-f, echo=F,fig.cap="percentage of multilingual elements over sentiment", warning=FALSE}
sent_global_f<-get_transformed_values(sent_global) #global sentiment values, relative
#dta_t$lxp[1]<-0
lxp_f<-get_transformed_values(dta_t$lxp) #
x1<-max(dta_t$lxp)
x2<-max(lxp_f)
x3<-x1/x2
#x2*x3
lxp_f_p<-lxp_f*x3
#lxpmatches
#plot(lxpmatches,type = "h")
#plot(lxp_f,type="h")
plot(lxp_f_p,type = "h",xlab="text corpus",ylab="occurences percentage %",main="sentiment/language correlation")
par(new=T)
plot(sent_global_f,type = "l",col=2,xaxt="n",yaxt="n",ann = F)

#scatter.smooth(1:length(sent_global),sent_global,.1,.1,type="l",family = "gaussian",col=2,xaxt="n",yaxt="n",ann = F)
```

summary:
```{r sum-lmer2, echo=FALSE, warning=FALSE}
print(lms)
# lm eval for row(5)=lxp
r<-5
rng<-2:4
get_lmer<-function(r,rng){
c0<-rng[1]-rng[1]+1
lmmax1<-which.max(lms$vcov[r,rng])
#lms$vcov[r,rng]
lmmax<-lms$vcov[r,lmmax1+c0]
lmmin1<-which.min(lms$vcov[r,rng])
lmmin<-lms$vcov[r,lmmin1+c0]
cnsmax<-colnames(lms$vcov)[lmmax1+c0]
cnsmin<-colnames(lms$vcov)[lmmin1+c0]
cin<-match(rng,c(lmmax1+c0,lmmin1+c0))
pmed<-rng[is.na(cin)]
cnsmed<-colnames(lms$vcov)[pmed]
#cns3<-colnames(lms$vcov)[3]
#cns4<-colnames(lms$vcov)[4]
lmdif1<-(lms$vcov[r,lmmax1+c0]-lms$vcov[r,lmmin1+c0])*10^4
lmdif2<-(lms$vcov[r,lmmax1+c0]-lms$vcov[r,pmed])*10^4
lmdif3<-lmdif1-lmdif2
dfeval<-c(round(lmmax,6),cnsmax,cnsmin,round(lmdif1,2),cnsmed,round(lmdif2,2),round(lmdif3,2))
}
```

Die Abhängigkeit der sentiment values vom Vorhandensein multilingualer Elemente läszt sich kurz umreiszen: Wir stellen den gröszten Zusammenhang mit [coefficient] ``r get_lmer(5,2:4)[1]`` bei ``r get_lmer(5,2:4)[2]`` fest, die Differenz zu ``r get_lmer(5,2:4)[3]`` beträgt ``r get_lmer(5,2:4)[4]``, zu ``r get_lmer(5,2:4)[5]`` ``r get_lmer(5,2:4)[6]`` Punkte, der Abstand der Abhängigkeit hier also ``r get_lmer(5,2:4)[7]`` Punkte.   

Die Abhängigkeit der sentiment values von der type/token ratio der Texte ebenfalls kurz umrissen: Wir stellen den gröszten Zusammenhang mit [coefficient] ``r get_lmer(6,2:4)[1]`` bei ``r get_lmer(6,2:4)[2]`` fest, die Differenz zu ``r get_lmer(6,2:4)[3]`` beträgt ``r get_lmer(6,2:4)[4]``, zu ``r get_lmer(6,2:4)[5]`` ``r get_lmer(6,2:4)[6]`` Punkte, der Abstand der Abhängigkeit hier also ``r get_lmer(6,2:4)[7]`` Punkte.   

### in words
summary:
```{r echo=F}
print (mfw_dta)
#knitr::kable(mfw_dta,5,5)
exc<-3
```
```{css echo=F}
pre {max-height: 400px;}
#most-probable-text p {font-family: Courier;}
```

Zum Beispiel: Die höchsten *sentiment* Werte, hier in [chapter:] ``r mfw_dta[[exc]]$max$chapter``, lassen sich in [text:] ``r mfw_dta[[exc]]$max$head`` finden. Die *most frequent words* dieses Abschnitts sind [duplicates:] ``r mfw_dta[[exc]]$max$words``, die niedrigsten finden sich im Text ``r mfw_dta[[exc]]$min$head`` mit ``r mfw_dta[[exc]]$min$words``.

## corpus play
Das Folgende zeigt einen Text, dem ein Algoritmus zugrundeliegt, der roughly die Wahrscheinlichkeit des Vorhandenseins eines Wortes an der jeweiligen Position im Text, über den gesamten Korpus betrachtet, bestimmt. Es tritt also jedes Wort dieses künstlichen Textes am wahrscheinlichsten an dieser Stelle auf, szsg. ein sehr simples *transformer* experiment, ohne jegliche Berücksichtigung semantisch-syntaktischer Kategorien.
```{r p-text, echo=F, warning=FALSE,caption="text generated by words with highest probability on fixed positions along text length"}
ptext<-c("sample","comment in","for","final","output")
ptext<-get_p(wc3)
#text<-cat(ptext)
text<-stri_join(ptext, collapse=" ")
#text
```

### most probable text
13506.ST: Uljana Wolf / GPTestee
<<< 
`r text`
<<< fin.

---

# B. REF:
</div>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeSourceEmbed("DYN_HA.Rmd");
});
</script>

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = false;
    options.smoothScroll = false;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
