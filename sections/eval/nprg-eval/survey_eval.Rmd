---
title: "NPRG survey evaluation"
author: "st."
date: "`r Sys.time()`"
output:
  #bookdown::pdf_document2:
   # extra_dependencies: ["float"]
  bookdown::html_document2:
    global_numbering: TRUE
    number_sections: TRUE
   # code_download: yes
    toc: yes
    toc_depth: 4
    toc_float:
       collapsed: no
       smooth_scroll: no
    self_contained: FALSE #TRUE for standalone html page knit
    css: https://school.dh-index.org/public/papers/011/style_HA.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rlang)
library(xml2)
library(stringi)
library(lme4)
library(R.utils)
```

```{r echo=T,warning=FALSE}
#print(head)
utest<-"[ani lo sonderzeichentest אני לאaäoöuüÄÖÜß]"
utest<-chr_unserialise_unicode(utest)
print(utest)
```

# HEAD
CHK: `r utest`       
NEUROPRAGMATIK rating studie

```{r,echo=F,warning=F,eval=TRUE}
#source("survey_src.R")
# scred<-read.csv("../../../local/R/cred_gener.csv")
# src<-scred$api[scred$url=="nprg-pure"]
cred<-read.csv("../../../../testeee/soscisrc.csv",sep=",")
src<-cred$link[1]
#eval(parse(src, encoding="UTF-8"))
source("import_nprg.r")
#d<-read.csv(src,sep="\t")
d<-ds
#getwd()
#qscheme<-read_xml("nprg-rating-q_layout_RND.xml")
qscheme<-read_xml("nprg-rating-q_layout.xml")
# img<-xml_find_all(qscheme,"page/image")
# img_href<-xml_attr(img,"src")
# img_png<-basename(img_href)
# regx1<-"(NPRG-)(.+)\\.png"
# repl1<-"\\2"
# img_ns<-gsub(regx1,repl1,img_png)
page<-xml_find_all(qscheme,"page")
pid1<-xml_attr(page,"ident")
pid1<-gsub("fern"," ####",pid1)
pstart<-grep("RN1",pid1)+1

m1<-grep("(QU[0-9]{1,2})",colnames(d)) #questioncolumns
pend<-pstart+length(m1)-1
pid<-pid1[pstart:pend]
#pid[1]
#d$MT01
#d<-ds
#d<-subset(d,d$MODE=="pretest")
d1<-subset(d,d$MODE=="interview")
d2<-subset(d1,d1$QUESTNNR=="nprg"|d1$QUESTNNR=="qnr2"|d1$QUESTNNR=="qnr4")
d3<-subset(d2,d2$MT01=="ja")
#dna<-!is.na(d1$SERIAL)
#sum(d3$FINISHED)
#sum(dna)
#d2<-subset(d1,dna)
#qarray<-unique(d$QU01)
#qarray<-levels(qarray)
#qreplace<-c("no concrete","index","request","undefined","n.a.")
#m<-match(qarray)
#m1<-grep("(QU[0-9]{1,2})",colnames(d3)) #questioncolumns
#k<-97
#messy data, missing QU19
#d$QU19[1]<-"<NA>"
#d$QU18
#putout(m1[1])
qstart<-m1[1]-1
#colnames(d3)[m1[1:20]]
putout<-function(k){
qx<-d3[,k]
#levels(qx)<-qreplace
#plot()
plot(qx,main=pid[k-qstart])
}
#putout(97)
ld<-length(d3$MODE)

```

```{r echo=F, warning=F}
words<-c("Buch", "Cola", "Zange", "Salz", "Kamm", "Messer", "Tasse","Stift","Ring","Vogel","Pfote","Handy")
raute<-"#####"
rating<-c("nichts konkretes","etwas benennen","etwas fordern","ist mir nicht klar")
png<-c("index","request","undef")
labels=c("inconcrete","name","request","unclear","N.A.")
```
# the test
## abstract
In dieser Studie wurden mittels eines rating tests Daten über die Zuordnung von picture stimuli zu 3 verschiedenen Bewertungskategorien erhoben. Das stimuli set bestand aus Bildern dreier Handgesten, die, mit jeweils 13 Wörtern kombiniert und randomisiert angezeigt, bewertet werden sollten. 
Es handelt sich hier um einen pretest des stimuli sets. Es sollten auf diese Weise in erster Linie Erkenntnisse darüber gewonnen werden, wie die Kombination von Geste und Wort wahrgenommen wird. In einer Fortführung würde darauf getestet werden, ob Kombinationen, die nicht oder nur bedingt sinnvoll zu interpretieren waren, Gehirnaktivitäten hervorrufen, die Rückschlüsse hinsichtlich eines u.U. erschwerten pragmatischen Verständnisses der jeweiligen Geste erlauben. Dabei würde in einem weiteren Test ein paralleles EEG aufgezeichnet und Korrelationen untersucht werden der Bewertung und der Messdaten.

## methoden
Die Bilder zeigten folgende Gesten:   

![INDEX](https://school.dh-index.org/public/api/rating-png/NPRG-index.png)   


![REQUEST](https://school.dh-index.org/public/api/rating-png/NPRG-request.png)    


![UNDEF](https://school.dh-index.org/public/api/rating-png/NPRG-undef.png)   

Kombiniert wurden die Gesten mit jeweils 12 Wörtern bzw. einem Unwort:   
- `r words`   
- `r raute`  

Zur Bewertung standen den participants 4 Auswahlmöglichkeiten zur Verfügung:   
- `r rating[1]`      
- `r rating[2]`   
- `r rating[3]`   
- `r rating[4]`   

### sample stimuli
Ein randomisiertes Bild+Wort sah dann folgendermaszen aus:


```{=html}
<style>
.container {
  position: relative;
  text-align: left;
  color: white;
}
.centered {
  position: absolute;
  font-size: 40pt;
  font-family: "Arial";
  color: yellow;
  top: 27%;
  left: 16%;
  transform: translate(-50%, -50%);
}
.center {
  display: inline;
  margin-left: 0;
  
  /*margin-right: auto;*/
  width: 30%;
}
.nopng {display: none;}
</style>
<div class="container">
<img class="center" src="https://school.dh-index.org/public/api/rating-png/NPRG-index.png">
<div class="centered">Buch</div>
</div>
```

# evaluation
```{r echo=F}
#attr(d$QU01,"word")<-"Buch"
#xml_attr(page,"ident")
#eval(d$QU01)
```
Es konnte festgestellt werden, dasz 

## raw data presentation 
live evaluated from dataset on server. graphics to come if theres data at all.  
dataset: `r ld` observations.

```{r,echo=F,warning=F}

##################################
listeval<-data.frame(m1=pid)
#colnames(listeval)<-colnames(d3)[m1]
#rating
subq<-d3[,m1]
for (k in 1:length(m1)){
listeval[k,"inconcrete"]<-sum(grepl(levels(subq$QU01)[1],subq[,k]))  
listeval[k,"name"]<-sum(grepl(levels(subq$QU01)[2],subq[,k]))  
listeval[k,"request"]<-sum(grepl(levels(subq$QU01)[3],subq[,k]))  
listeval[k,"unclear"]<-sum(grepl(levels(subq$QU01)[4],subq[,k]))  
listeval[k,"NA"]<-sum(grepl(levels(subq$QU01)[5],subq[,k]))  

}
# rownames(listeval)<-listeval$m1
# listeval$m1[which.max(listeval$name)]
# t6<-head(listeval[order(listeval$name,decreasing = T)])
# t6
df<-listeval
### sort dataframe:
#ordering dataframe by column 1
# df[with(df,order(df[,3],decreasing = T)), ]
# #ordering dataframe by column name 'a'
# df[with(df,order(df[,"a"])), ]
# df[order(df[[var]]),]
# df[order(df[,var]),]

#remove undefsalz for messy data
dfc<-listeval
dfc<-subset(dfc,dfc$m1!="undefsalz")
#dfc<-dfc[with(dfc,order(dfc[,1],decreasing = F)), ]
#dfc<-dfc[1:38,]
# dfc.name<-dfc[with(dfc,order(dfc[,3],decreasing = T)), ]
# dfc.req<-dfc[with(dfc,order(dfc[,4],decreasing = T)), ]
# dfc.inconc<-dfc[with(dfc,order(dfc[,2],decreasing = T)), ]
# dfc.unclear<-dfc[with(dfc,order(dfc[,5],decreasing = T)), ]
# plot(dfc.name[2,2:5])

#library(R.utils)
df2<-dfc
df2$png<-stri_extract_all_regex(df2$m1,"index|undef|request",simplify = T)
regxword<-paste0("(",paste(decapitalize(words),collapse = "|"),"|####)")
df2$word<-stri_extract_all_regex(df2$m1,regxword,simplify = T)
# lm(df2$name~df2$request)
# lm(df2$request~df2$png)
# lm(df2$unclear~df2$png)
# u<-runif(20)
# df2$index<-df2$png=="index"
# df2$req<-df2$png=="request"
# df2$undef<-df2$png=="undef"
df3<-df2

########
#df3<-dfc
df3$response<-1
lo<-length(df2$name)
lo1<-lo+1
lo2<-lo*2+1
lo3<-lo*3+1
lo4<-lo*4

df3[lo1:lo4,"response"]<-1
#df3$response<-append(df3$response,39:114,length(df3$response))
#df3$response[1:38*3]<-0
df3$response[1:lo]<-df2$name
df3$response[lo1:lo2]<-df2$request
#77:114
df3$response[lo2:lo3]<-df2$inconcrete
df3$response[lo3:lo4]<-df2$unclear
#df3[lo1:lo4,14]<-1

df3$resp_cat[1:lo]<-"name"
df3$resp_cat[lo1:lo2]<-"request"
df3$resp_cat[lo2:lo3]<-"undef"
df3$resp_cat[lo3:lo4]<-"unclear"

df3$resp_word[1:lo]<-df2$word
df3$resp_word[lo1:lo2]<-df2$word
df3$resp_word[lo2:lo3]<-df2$word
df3$resp_word[lo3:lo4]<-df2$word

df3$resp_png[1:lo]<-df2$png
df3$resp_png[lo1:lo2]<-df2$png
df3$resp_png[lo2:lo3]<-df2$png
df3$resp_png[lo3:lo4]<-df2$png

#df3$resp_word[which.max(df3$response)]
df4<-data.frame(response_value=df3$response,response_lang=df3$resp_cat,png=df3$resp_png,word=df3$resp_word)



#lm(response_value~word,df4)

#df4$index<-0
df5<-df4
t<-df4$response_lang=="name"
#df4$index<-df4$response_lang=="name"
#df4$request<-df4$response_lang=="request"
#df4$undef<-df4$response_lang=="un"
df5$response_lang[t]<-"index"
df5$true<-df5$png==df5$response_lang

# library(lme4)
# lm1<-lmer(response_value~word+(png|word),df4)
# summary(lm1)

#truth values: how often ideal answer?
#ideal 13x3 = 39 kombinations = 13 each

#lmer
# plot(df4$response_value, pch=19)
# abline(a=10, b=2, col="grey")
# regxy = lm(y~x)
# abline(regxy)
# text(6.6, 18, expression(hat(E)(y) == hat(beta)[0] + hat(beta)[1]*x), pos=4)
# arrows(7.4, 18.8, 7.4, coef(regxy)%*%c(1,7.4), length=.15)
# segments(x, y, x, fitted(regxy), lty=3)

##################
#x = runif(30,0,10)
#x[28] = 8.5
#y = m + 2*x + rnorm(o)*3 #10+
m<-39 #ideal (correct) answer / picture
#m<-max(df4$response_value)
o<-length(df5$response_value) # anzahl answers 
#y<-1:m
#m<-o
x = runif(o,0,m) # ideal random distribution over observation
x<-1:152
y = df5$response_value # real distribution
#mean(x)
response<-y
expected<-x
#
# pch = 1 open circle, 2 triangle, 3 plus, 4 x, 5 diamond, 6 inverted triangle; 19 solid circle
#
# curve(rnorm(x))
# plot(x, y, pch=19)
# abline(a=m, b=2) #a=10
# text(5.8, 18, expression(E(y) == beta[0] + beta[1]*x), pos=4)
# arrows(6, 18.8, 5.9, 21.8, length=.15)
# segments(x, y, x, 10+2*x, lty=3)
# dev.off()
#
# Figure 1.2
#
#abline(regxy)
#a<-mean(df5$response_value)
dplot<-data.frame(expected=x,response=y)
plot.new()
#plot(dplot, pch=18,main="chosen label vs. ideal selection",xlab="ideal-fitted",ylab="selection")

plot(x, y, pch=18,main="chosen label vs. expected selection",xlab="fitted",ylab="selection")
abline(a=13, b=0,col="grey")
regxy = lm(response~expected)
#lm2<-lm(dplot)
#summary(lm2)
#summary(regxy)
#summary(lm(y~x))
abline(regxy)
text(25, 30, "Ideal", pos=4)
arrows(28, 28, 28, 13, length=.15)
text(5, 20, "Abweichung", pos=4,col=2)
arrows(7.4, 18.8, 7.4, coef(regxy)%*%c(1,7.4), length=.15,col=2)
segments(x, y, x, fitted(regxy), lty=3)
#dev.off()
stimuli<-paste(df5$png,df5$word)
lm1<-lmer(response_value~response_lang+(word|png),df5)
lm3<-lm(response_value~stimuli,df5)
sum1<-summary(lm3)
#sum1$coefficients[1]
#sum1$coefficients[which.min(sum1$coefficients)]
#(sum1$coefficients[which.min(sum1$coefficients)])
#plot(lm1)
#which.max(sum1$coefficients)
coef1<-data.frame(sum1$coefficients)
coef2<-coef1[order(coef1$t.value,decreasing = T),]
#coef1[which.min(coef1$t.value),]
#coef1[which.max(coef1$t.value),]
rownames(coef1)[1]<-"index ####"
p1<-df5$response_value/64 #prozent richtige antworten
df5$response_p<-p1
df5$response_exp<-1
summary(lm(df5$response_p~df5$response_lang))

source("lme.R")
#plot(regxy)
#regxy$effects

```

```{r descriptive,echo=F,warning=F,eval=T}
# p_array<-grep("_",colnames(pngcount))
# meandf<-lapply(pngcount[,p_array], mean,na.rm=T)
#par(new=F)
par(las=3,cex.axis=0.6)
barplot(unlist(meandf),main="normalized distribution",ylab="mean % of selections over participants")


```

```{r,echo=F,warning=F,eval=TRUE}

for (k in m1){
putout(k)
}

```


